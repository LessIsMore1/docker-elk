## Example found at: https://blog.sstorie.com/importing-iis-logs-into-elasticsearch-with-logstash/
## Combined this with default from: https://github.com/deviantony/docker-elk
##
## Add your filters / logstash plugins configuration here
################################################################
## This file was built with the help of this tutorial:
##   https://adammills.wordpress.com/2014/02/21/logstash-and-iis/
##
## The full logstash docs are here: http://logstash.net/docs/1.4.2/
#

input {
	tcp {
		port => 5000
	}
}

## We have IIS configured to use a single log file for all sites
#   because logstash can't handle parsing files in different
#   directories if they have the same name.
#
#input {  
#  file {
#    type => "iis-w3c"
#    path => "C:/inetpub/logs/LogFiles/W3SVC*/*.log"
#  }
#}

filter {  
  ## Ignore the comments that IIS will add to the start of the W3C logs
  #
  if [message] =~ "^#" {
    drop {}
  }
  if [message] =~ / app / {
    grok {
      ## Very helpful site for building these statements:
      #   http://grokdebug.herokuapp.com/
      #
      # This is configured to parse out every field of IIS's W3C format when
      #   every field is included in the logs
      #
      match => ["message", "%{TIMESTAMP_ISO8601:log_timestamp} %{WORD:siteName} %{NOTSPACE:computerName} %{IP:serverIP} %{WORD:method} %{URIPATH:uriStem} %{NOTSPACE:uriQuery} %{NUMBER:port} %{NOTSPACE:username} %{IP:lbIP} %{NOTSPACE:protocolVersion} %{NOTSPACE:userAgent} %{NOTSPACE:cookie} %{NOTSPACE:referer} %{NOTSPACE:host} %{NUMBER:status} %{NUMBER:substatus} %{NUMBER:win32response} %{NUMBER:bytesSent} %{NUMBER:bytesReceived} %{NUMBER:timetaken} %{NOTSPACE:clientIP} %{NOTSPACE:cfForwardFor} %{NOTSPACE:cfRay} %{NOTSPACE:cfIpCountry} %{NOTSPACE:cfVisitor}"]
    }
  } else {
    grok {
      match => ["message", "%{TIMESTAMP_ISO8601:log_timestamp} %{WORD:siteName} %{NOTSPACE:computerName} %{IP:serverIP} %{WORD:method} %{URIPATH:uriStem} %{NOTSPACE:uriQuery} %{NUMBER:port} %{NOTSPACE:username} %{IP:lbIP} %{NOTSPACE:protocolVersion} %{NOTSPACE:userAgent} %{NOTSPACE:cookie} %{NOTSPACE:referer} %{NOTSPACE:host} %{NUMBER:status} %{NUMBER:substatus} %{NUMBER:win32response} %{NUMBER:bytesSent} %{NUMBER:bytesReceived} %{NUMBER:timetaken} %{NOTSPACE:clientIP} %{NOTSPACE:cfForwardFor} %{NOTSPACE:cfRay} %{NOTSPACE:cfIpCountry} %{NOTSPACE:cfVisitor}"]

    }
  }

  ## Split uriStem into uriPaths
  #
  if !( [uriStem] == "/" ) {
    mutate {
      add_field => { "uriArray" => "%{uriStem}" }
    }
    mutate {
      gsub => [ "uriArray", "/", " "] 
    }
    mutate {
      strip => [ "uriArray" ] 
    }
    csv {
      source => "uriArray"
      columns => [ "1", "2", "3", "4", "5", "6", "7" ]
      separator => " "
      target => "uriPath"
    }
    mutate {
      remove_field => [ "uriArray" ]
    }
  }
  
  ## Split uriQuery into key-value pairs
  #
  kv {
    source => "uriQuery"
    field_split => "&"
    target => "query"
  }

  ## Set the Event Timesteamp from the log
  #
  date {
    match => [ "log_timestamp", "YYYY-MM-dd HH:mm:ss" ]
      timezone => "Etc/UTC"
  }

  ## If the log record has a value for 'bytesSent', then add a new field
  #   to the event that converts it to kilobytes
  #
  if [bytesSent] {
    ruby {
      code => "event.set('kilobytesSent', event.get('bytesSent').to_i / 1024.0)"      
    }
  }

  ## Do the same conversion for the bytes received value
  #
  if [bytesReceived] {
    ruby {
      code => "event.set('kilobytesReceived', event.get('bytesReceived').to_i / 1024.0)"
    }
  }

  ## Perform some mutations on the records to prep them for Elastic
  #
  mutate {
    ## Convert some fields from strings to integers
    #
    convert => ["bytesSent", "integer"]
    convert => ["bytesReceived", "integer"]
    convert => ["timetaken", "integer"]

    ## Create a new field for the reverse DNS lookup below
    #
    add_field => { "clientHostname" => "%{clientIP}" }

    ## Finally remove the original log_timestamp field since the event will
    #   have the proper date on it
    #
    remove_field => [ "log_timestamp"]
  }


  ## Do a reverse lookup on the client IP to get their hostname.
  #
  dns {
    ## Now that we've copied the clientIP into a new field we can
    #   simply replace it here using a reverse lookup
    #
    action => "replace"
    reverse => ["clientHostname"]
  }

  ## Parse out the user agent
  #
    useragent {
        source=> "useragent"
        prefix=> "browser"
    }

}

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
	}
}

## We're only going to output these records to Elasticsearch so configure
#   that.
#
#output {  
#  elasticsearch {
#    embedded => false
#    host => "localhost"
#    port => 9200
#    protocol => "http"
#    #
#    ## Log records into month-based indexes
#    #
#    index => "%{type}-%{+YYYY.MM}"
#  }
#
#  ## stdout included just for testing
#  #
#  #stdout {codec => rubydebug}
#}


